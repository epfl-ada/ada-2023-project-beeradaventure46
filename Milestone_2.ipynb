{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 : Project proposal and initial analyses üçª\n",
    "\n",
    "<hr style=\"clear:both\">\n",
    "This notebook was made for the ADA course at EPFL (CS-401). \n",
    "\n",
    "Group : BeerADAventure46\n",
    "\n",
    "**Authors:** \\\n",
    "[Agatha Hunter](https://people.epfl.ch/agatha.hunter)\\\n",
    "[Anne-Val√©rie Preto](https://people.epfl.ch/anne-valerie.preto)\\\n",
    "[Tristan Carruzzo](https://people.epfl.ch/tristan.carruzzo)\\\n",
    "[Thamin Maurer](https://people.epfl.ch/thamin.maurer)\\\n",
    "[Victor Dubien](https://people.epfl.ch/victor.dubien)\n",
    "\n",
    "\n",
    "**Supervisor:**\\\n",
    "[Beatriz Borges](https://people.epfl.ch/beatriz.borges)\n",
    "<hr style=\"clear:both\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "## Project proposal  üìå\n",
    "\n",
    "**Influence of the serving style on the tasting profile**:\n",
    "\n",
    "Goal of the project: Use the textual reviews to find for each beer how it was served (either bottle, can or draft) and find how it influences the tasting profile.\n",
    "\n",
    "Different serving styles may be adopted in different regions or for different types of beer.  The influence of the serving style could influence not only the appearance, but also the aroma, the palate or the taste.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO LIST FOR THE GROUP:\n",
    "\n",
    "<input type=\"checkbox\" checked > New architecture of file\n",
    "\n",
    "<input type=\"checkbox\" checked > Create functions to import and convert initial files\n",
    "\n",
    "<input type=\"checkbox\" checked > More comments on the dataset -> distribution, viz\n",
    "\n",
    "<input type=\"checkbox\" checked > For any filtering: how, why ?\n",
    "\n",
    "<input type=\"checkbox\"> Choose a NLP method -> comment as much as possible, some trials \n",
    "\n",
    "<input type=\"checkbox\" checked > E-mail the proposition to Beatriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from langdetect import detect\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "\n",
    "from textstat import flesch_reading_ease, flesch_kincaid_grade, gunning_fog, smog_index, automated_readability_index, coleman_liau_index, linsear_write_formula, dale_chall_readability_score, text_standard\n",
    "from utils import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_path = './data/BeerAdvocate/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets üìÇ\n",
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firt time imports : \n",
    "# Convert txt to csv (function in the utils.py file)\n",
    "\n",
    "#ratings = convert_txt_to_csv(input_file='ratings.txt', export=True, file_name='ratings')\n",
    "#reviews = convert_txt_to_csv(input_file='reviews.txt', export=True, file_name='reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files already converted, so we can load them directly\n",
    "\n",
    "reviews = pd.read_csv(dataset_path + 'reviews.csv')\n",
    "beers = pd.read_csv(dataset_path + 'beers.csv')\n",
    "breweries = pd.read_csv(dataset_path + 'breweries.csv')\n",
    "users = pd.read_csv(dataset_path + 'users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial datasets analysis üîé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beers dataset üç∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(beers.sample(3))\n",
    "print('Shape of beers : ', beers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of beers id and beer name\n",
    "print('Number of different beers id:', len(beers.beer_id.unique()))\n",
    "print('Number of different beers name:', len(beers.beer_name.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "**Initial comments about the dataset**\n",
    "\n",
    "-Some beers have the same name! In order to avoid confusion, we will drop the column beer_name (and brewery_name) from the dataset.\n",
    "\n",
    "-As we will not use the RateBeer dataset, we can also drop the column nbr_matched_valid_ratings and avg_matched_valid_ratings.  \n",
    "\n",
    "-The column bros_score only reflect the ratings from the two creators of the website, so we can also drop it.  \n",
    "\n",
    "-ba_score represents the percentage (rounded to the tenth for depth) of raters who gave the beer a 3.75 or higher as long as the beers as at least 10 ratings.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the percentage of missing values per columm\n",
    "plt.figure()\n",
    "(beers.isna().sum() / len(beers) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()\n",
    "\n",
    "#print how many values are missing in each column in %\n",
    "print('How many values missing per column in %:')\n",
    "display(beers.isna().sum()/ len(beers) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "**More comments about the dataset**\n",
    "\n",
    "We see that more than 80% of the beers do not have a z-score value. We can drop this column alongside avg_computed and compute them manually later if needed from the reviews dataset. \n",
    "\n",
    "80% of the beers have no ba_score value, so we can also drop it and compute it later if needed.\n",
    "\n",
    "The other columns with NaN such as avg_matched_valid_ratings, avg_computed or bros_score are not usefull in our analysis since we only look at the BeerAdvocate reviews.\n",
    "\n",
    "However, the abv, which represents the alcohol percentage in a beer, is missing for approximately 12%.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_filtered = beers.drop(columns=['beer_name', \n",
    "                            'brewery_name',\n",
    "                            'bros_score',\n",
    "                            'ba_score',\n",
    "                            'nbr_matched_valid_ratings',\n",
    "                            'avg_matched_valid_ratings',\n",
    "                            'zscore',\n",
    "                            'avg_computed']).copy(deep=True)\n",
    "\n",
    "beers_filtered.rename(columns={'nbr_ratings': 'beer_nbr_ratings',\n",
    "                               'nbr_reviews': 'beer_nbr_reviews'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_filtered.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "beers_filtered['style'].value_counts(normalize=False).head(10).plot(kind='barh', title='10 most common beer styles')\n",
    "plt.xlabel('Number of beers')\n",
    "plt.subplot(1, 2, 2)\n",
    "beers_filtered['beer_nbr_reviews'].hist(bins=50,log=True)\n",
    "plt.title('Number of reviews per beer')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of reviews')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show boxplot of abv for each beer style\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.boxplot(y='style', x='abv', data=beers_filtered, fliersize=3)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.title('Boxplot of abv for each beer style')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the beers by style and compute the median of abv for each style\n",
    "median_abv_by_style = beers_filtered.groupby('style')['abv'].median()\n",
    "display(median_abv_by_style.sample(3))\n",
    "\n",
    "# fill the missing abv values with the median of abv for the style of each beer\n",
    "beers_filtered['abv'] = beers_filtered.apply(lambda x: median_abv_by_style[x['style']] if pd.isna(x['abv']) else x['abv'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beers_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "We are left with a dataset containing 280823 beers. We are only missing some values for avg as some beers do not have any ratings/reviews. They will be removed later when merging with the reviews dataset anyway.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breweries dataset üè≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(breweries.sample(3))\n",
    "print('Shape of breweries : ', breweries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the percentage of missing values per columm\n",
    "plt.figure()\n",
    "(breweries.isna().sum() / len(breweries) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "This dataset has no missing values, we will simply rename the columns and drop the brewery name.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_filtered = breweries.drop(columns=['name']).copy(deep=True)\n",
    "breweries_filtered = breweries.copy(deep=True)\n",
    "\n",
    "breweries_filtered.rename(columns={'id':'brewery_id',\n",
    "                                   'location':'brewery_location',\n",
    "                                   'nbr_beers':'brewery_nbr_beers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breweries_filtered.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some breweries have weird location values, should find a way to clean them\n",
    "print('Number of breweries with a weird location value:', len(breweries_filtered[breweries_filtered['brewery_location'].str.contains('<', na=False)]))\n",
    "\n",
    "# should manully add the us state of the 35 breweries because it corresponds to to 15'319 reviews.\n",
    "\n",
    "# for loc in breweries_filtered[breweries_filtered['brewery_location'].str.contains('<', na=False)]['brewery_location'].unique():\n",
    "#     print(loc) # print the strange values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually adding the location for those 35 breweries\n",
    "\n",
    "#obtain the brewery_id of the 35 breweries\n",
    "strange_id = breweries_filtered[breweries_filtered['brewery_location'].str.contains('<', na=False)]['brewery_id'].unique()\n",
    "strange_id\n",
    "\n",
    "# create a dic with the brewery_id as key and unknwon as value\n",
    "dic = {}\n",
    "for i in strange_id:\n",
    "    dic[i] = 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes as input the brewery_id and a location and change the location of the brewery with the given id in the dictionary dic \n",
    "def change_location(brewery_id, us_state):\n",
    "    location = 'United States, ' + us_state\n",
    "    dic[brewery_id] = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first element of dic that has value unknown and print its location\n",
    "for key, value in dic.items():\n",
    "    if value == 'unknown':\n",
    "        print('Brewery id:', key)\n",
    "        # print('Brewery name:', breweries_filtered[breweries_filtered['brewery_id'] == key]['name'].values[0])\n",
    "        print('Strange location:',breweries_filtered[breweries_filtered['brewery_id'] == key]['brewery_location'].values[0])        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the location in dic\n",
    "\n",
    "change_location(brewery_id=2434,us_state='New Mexico')\n",
    "change_location(brewery_id=2730,us_state='Wisconsin')\n",
    "change_location(brewery_id=1551,us_state='California')\n",
    "change_location(brewery_id=1552,us_state='Michigan')\n",
    "change_location(brewery_id=2710,us_state='California')\n",
    "change_location(brewery_id=3681,us_state='Ohio')\n",
    "change_location(brewery_id=2413,us_state='California')\n",
    "change_location(brewery_id=1793,us_state='Virginia')\n",
    "change_location(brewery_id=6045,us_state='New Jersey')\n",
    "change_location(brewery_id=2776,us_state='New York')\n",
    "change_location(brewery_id=1751,us_state='Texas')\n",
    "change_location(brewery_id=1554,us_state='Georgia')\n",
    "change_location(brewery_id=1961,us_state='Maine')\n",
    "change_location(brewery_id=4927,us_state='South Carolina')\n",
    "change_location(brewery_id=23973,us_state='Maine')\n",
    "change_location(brewery_id=2512,us_state='California')\n",
    "change_location(brewery_id=6416,us_state='New Jersey')\n",
    "change_location(brewery_id=2104,us_state='Oregon')\n",
    "change_location(brewery_id=3079,us_state='Washington')\n",
    "change_location(brewery_id=2410,us_state='Michigan')\n",
    "change_location(brewery_id=1931,us_state='Ohio')\n",
    "change_location(brewery_id=1553,us_state='Maine')\n",
    "change_location(brewery_id=1550,us_state='Colorado')\n",
    "change_location(brewery_id=32764,us_state='Illinois')\n",
    "change_location(brewery_id=8451,us_state='Wyoming')\n",
    "change_location(brewery_id=5114,us_state='California')\n",
    "change_location(brewery_id=1802,us_state='North Carolina')\n",
    "change_location(brewery_id=1819,us_state='Minnesota')\n",
    "change_location(brewery_id=200,us_state='California')\n",
    "change_location(brewery_id=918,us_state='Florida')\n",
    "change_location(brewery_id=4343,us_state='California')\n",
    "change_location(brewery_id=9765,us_state='New York')\n",
    "change_location(brewery_id=1927,us_state='Colorado')\n",
    "change_location(brewery_id=28908,us_state='Utah')\n",
    "change_location(brewery_id=70,us_state='Oregon')\n",
    "change_location(brewery_id=1567,us_state='Hawaii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the location of the breweries in the breweries_filtered dataframe\n",
    "for key, value in dic.items():\n",
    "    breweries_filtered.loc[breweries_filtered['brewery_id'] == key, 'brewery_location'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many different locations are there that contain United States\n",
    "print('Number of different locations that contain United States:', len(breweries_filtered[breweries_filtered['brewery_location'].str.contains('United States')]['brewery_location'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the number of breweries per state as barh\n",
    "plt.figure(figsize=(15, 15))\n",
    "breweries_filtered[breweries_filtered['brewery_location'].str.contains('United States')]['brewery_location'].value_counts().plot(kind='barh')\n",
    "plt.title('Number of breweries per state')\n",
    "plt.xlabel('Number of breweries')\n",
    "plt.ylabel('State')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "breweries_filtered['brewery_nbr_beers'].hist(bins=50, log=True)\n",
    "plt.title('Number of beers per brewery')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of beers')\n",
    "plt.subplot(1, 2, 2)\n",
    "breweries_filtered['brewery_location'].value_counts(normalize=False).head(10).plot(kind='barh', title='10 most common brewery locations')\n",
    "plt.xlabel('Number of breweries')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users dataset üë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(users.sample(3))\n",
    "print('Shape of users : ', users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(users.isna().sum() / len(users) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "We are only missing information about when the user joined the website and locations. (and 1 username, which we drop anyway)\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_filtered = users.drop(columns=['user_name']).copy(deep=True)\n",
    "\n",
    "users_filtered.rename(columns={'nbr_ratings':'user_nbr_ratings',\n",
    "                               'nbr_reviews':'user_nbr_reviews',\n",
    "                               'joined':'user_joined',\n",
    "                               'location':'user_location'}, inplace=True)\n",
    "\n",
    "users_filtered.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "users_filtered['user_nbr_reviews'].hist(bins=50, log=True)\n",
    "plt.title('Number of reviews per users')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Number of reviews')\n",
    "plt.subplot(1, 2, 2)\n",
    "users_filtered['user_location'].value_counts(normalize=False).head(10).plot(kind='barh', title='10 most common user locations')\n",
    "plt.xlabel('Number of users')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "We observe that many users have no reviews at all, they will be removed from the dataset when merging. Also, the 10 most common user location are all in the US.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews dataset üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(reviews.sample(3))\n",
    "print('Shape of reviews : ', reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "(reviews.isna().sum() / len(reviews) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure that all the NaN are in the same rows\n",
    "\n",
    "# print the number of rows that contains a NaN value for each column ['overall', 'taste', 'palate', 'aroma', 'appearance']\n",
    "print('Number of rows with NaN values for each column :')\n",
    "for col in ['overall', 'taste', 'palate', 'aroma', 'appearance']:\n",
    "    print(col, ':', len(reviews[reviews[col].isna()]))\n",
    "    \n",
    "missing_values = reviews[['overall', 'taste', 'palate', 'aroma', 'appearance']].isna()\n",
    "missing_values['all_missing'] = missing_values.all(axis=1)\n",
    "print(missing_values['all_missing'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "\n",
    "All the missing values are in the same rows, and they represent less than 1.5% of the dataset. We can drop them.\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the columns that are not useful for our analysis\n",
    "reviews_filtered = reviews.drop(columns=['user_name', 'beer_name', 'brewery_name']).copy(deep=True)\n",
    "\n",
    "# remove the column abv because we have the information in the beers dataframe\n",
    "reviews_filtered.drop(columns=['abv'], inplace=True)\n",
    "\n",
    "#remove rows in reviews_filtered that have all_missing True in missing_values\n",
    "reviews_filtered = reviews_filtered[~missing_values['all_missing']].copy(deep=True)\n",
    "\n",
    "display(reviews_filtered.sample(3))\n",
    "print('Shape of reviews_filtered : ', reviews_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of NaN in columns ['overall', 'taste', 'palate', 'aroma', 'appearance']\n",
    "print('Number of NaN values for each column :')\n",
    "for col in ['overall', 'taste', 'palate', 'aroma', 'appearance']:\n",
    "    print(col, ':', len(reviews_filtered[reviews_filtered[col].isna()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show boxplot for each rating column, appearance, aroma, palate, taste and overall\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=reviews_filtered[['appearance', 'aroma', 'palate', 'taste', 'overall']])\n",
    "plt.title('Beer Ratings by Aspect')\n",
    "plt.xlabel('Aspect')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge datasets üîó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge reviews with users and beers and breweries\n",
    "df_merged = reviews_filtered.merge(beers_filtered, how='left', on=['beer_id', 'brewery_id', 'style'])\n",
    "df_merged = df_merged.merge(users_filtered, how='left', on='user_id')\n",
    "df_merged = df_merged.merge(breweries_filtered, how='left', on='brewery_id')\n",
    "\n",
    "display(df_merged.sample(1))\n",
    "print('Shape of df_merged : ', df_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter datasets ‚úÇÔ∏è\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Danger:</b> Comment EVERY filtering\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the percentage of missing values per columm\n",
    "plt.figure()\n",
    "(df_merged.isna().sum() / len(df_merged) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many reviews have strange brewery location ?\n",
    "print('Number of reviews with a weird location value:', len(df_merged[df_merged['brewery_location'].str.contains('<', na=False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many reviews have no abv value ?\n",
    "print('Number of reviews with no abv value:', len(df_merged[df_merged['abv'].isna()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can replace missing user_joined values with the date of the first review of the user\n",
    "df_merged['first_review'] = df_merged.groupby('user_id')['date'].transform('min')\n",
    "df_merged['user_joined'] = df_merged['user_joined'].fillna(df_merged['first_review'])\n",
    "df_merged.drop(columns=['first_review'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the percentage of reviews with at least one NaN value ?\n",
    "print('Percentage of reviews with at least one NaN value :', len(df_merged[df_merged.isna().any(axis=1)]) / len(df_merged) * 100)\n",
    "print('This corresponds to', len(df_merged[df_merged.isna().any(axis=1)]), 'reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the percentage of missing values per columm\n",
    "plt.figure()\n",
    "(df_merged.isna().sum() / len(df_merged) * 100).plot(kind='barh', title='Percentage of missing values per column')\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_merged.to_csv(dataset_path + 'BeerAdvocateMerged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data enrichment üç∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path + 'BeerAdvocateMerged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>style</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>appearance</th>\n",
       "      <th>aroma</th>\n",
       "      <th>palate</th>\n",
       "      <th>taste</th>\n",
       "      <th>overall</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>beer_nbr_ratings</th>\n",
       "      <th>beer_nbr_reviews</th>\n",
       "      <th>avg</th>\n",
       "      <th>abv</th>\n",
       "      <th>user_nbr_ratings</th>\n",
       "      <th>user_nbr_reviews</th>\n",
       "      <th>user_joined</th>\n",
       "      <th>user_location</th>\n",
       "      <th>brewery_location</th>\n",
       "      <th>name</th>\n",
       "      <th>brewery_nbr_beers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1180153</th>\n",
       "      <td>6076</td>\n",
       "      <td>651</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>1290078000</td>\n",
       "      <td>garuda.417017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>A - Hazed deep golden with a towering white he...</td>\n",
       "      <td>5272</td>\n",
       "      <td>1288</td>\n",
       "      <td>4.17</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1155</td>\n",
       "      <td>471</td>\n",
       "      <td>1.263812e+09</td>\n",
       "      <td>United States, Pennsylvania</td>\n",
       "      <td>United States, New York</td>\n",
       "      <td>Ithaca Beer Company</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752470</th>\n",
       "      <td>48508</td>\n",
       "      <td>13839</td>\n",
       "      <td>Euro Dark Lager</td>\n",
       "      <td>1243591200</td>\n",
       "      <td>ffejherb.103416</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>22oz. bomber into shaker pint on 5/27/09. Than...</td>\n",
       "      <td>365</td>\n",
       "      <td>183</td>\n",
       "      <td>3.77</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1661</td>\n",
       "      <td>1647</td>\n",
       "      <td>1.161166e+09</td>\n",
       "      <td>United States, Pennsylvania</td>\n",
       "      <td>United States, California</td>\n",
       "      <td>Port Brewing</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757181</th>\n",
       "      <td>65987</td>\n",
       "      <td>23145</td>\n",
       "      <td>Winter Warmer</td>\n",
       "      <td>1333447200</td>\n",
       "      <td>georgiabeer.87185</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.42</td>\n",
       "      <td>Overall I was a little disappointed in this be...</td>\n",
       "      <td>79</td>\n",
       "      <td>28</td>\n",
       "      <td>4.04</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3194</td>\n",
       "      <td>2320</td>\n",
       "      <td>1.152094e+09</td>\n",
       "      <td>United States, Georgia</td>\n",
       "      <td>United States, North Carolina</td>\n",
       "      <td>Fullsteam Brewery</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         beer_id  brewery_id            style        date            user_id  \\\n",
       "1180153     6076         651     American IPA  1290078000      garuda.417017   \n",
       "752470     48508       13839  Euro Dark Lager  1243591200    ffejherb.103416   \n",
       "1757181    65987       23145    Winter Warmer  1333447200  georgiabeer.87185   \n",
       "\n",
       "         appearance  aroma  palate  taste  overall  rating  \\\n",
       "1180153         5.0    5.0     4.5    4.0      5.0    4.55   \n",
       "752470          4.0    4.0     4.0    4.0      4.0    4.00   \n",
       "1757181         3.5    4.0     3.5    3.0      3.5    3.42   \n",
       "\n",
       "                                                      text  beer_nbr_ratings  \\\n",
       "1180153  A - Hazed deep golden with a towering white he...              5272   \n",
       "752470   22oz. bomber into shaker pint on 5/27/09. Than...               365   \n",
       "1757181  Overall I was a little disappointed in this be...                79   \n",
       "\n",
       "         beer_nbr_reviews   avg  abv  user_nbr_ratings  user_nbr_reviews  \\\n",
       "1180153              1288  4.17  7.5              1155               471   \n",
       "752470                183  3.77  6.5              1661              1647   \n",
       "1757181                28  4.04  8.8              3194              2320   \n",
       "\n",
       "          user_joined                user_location  \\\n",
       "1180153  1.263812e+09  United States, Pennsylvania   \n",
       "752470   1.161166e+09  United States, Pennsylvania   \n",
       "1757181  1.152094e+09       United States, Georgia   \n",
       "\n",
       "                      brewery_location                 name  brewery_nbr_beers  \n",
       "1180153        United States, New York  Ithaca Beer Company                193  \n",
       "752470       United States, California         Port Brewing                 68  \n",
       "1757181  United States, North Carolina    Fullsteam Brewery                 96  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df :  (2557577, 23)\n"
     ]
    }
   ],
   "source": [
    "display(df.sample(3))\n",
    "print('Shape of df : ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving type (naive approach) üçæü•§üö∞\n",
    "\n",
    ">Since our goal is to look at the influence of the serving style, we need to know how each beer was served. \n",
    "For now, we use a naive approach. We only look at whether a word specific to as service style has been used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 different columns according to the text review, \"bottle\", \"can\", \"draft\"\n",
    "\n",
    "bottle = ['bottle', 'bottled', 'bottles']\n",
    "can = [' can ', 'canned', ' cans ']\n",
    "draft = ['draft', 'draught', 'tap', 'taps']\n",
    "# Create different columns if review text contains the word\n",
    "df['bottle'] = df['text'].astype(str).apply(lambda x: any(ele in x.lower() for ele in bottle))\n",
    "df['can'] = df['text'].astype(str).apply(lambda x: any(ele in x.lower() for ele in can))\n",
    "df['draft'] = df['text'].astype(str).apply(lambda x: any(ele in x.lower() for ele in draft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove every row where columns bottle, can and draft are all False\n",
    "df = df[df[['bottle', 'can', 'draft']].any(axis=1)]\n",
    "# display(df.sample(3))\n",
    "# print('We have {} valid reviews'.format(df.shape[0]))\n",
    "\n",
    "# remove every row with more than 1 true\n",
    "df = df[df[['bottle', 'can', 'draft']].sum(axis=1) == 1]\n",
    "# display(df.sample(3))\n",
    "# print('We have {} valid reviews'.format(df.shape[0]))\n",
    "\n",
    "#create a new column with the serving type\n",
    "df['serving_type'] = df[['bottle', 'can', 'draft']].idxmax(axis=1)\n",
    "\n",
    "# drop the columns bottle, can and draft\n",
    "df.drop(['bottle', 'can', 'draft'], axis=1, inplace=True)\n",
    "\n",
    "display(df.sample(3))\n",
    "\n",
    "# print the number of reviews for each serving type\n",
    "df['serving_type'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(review, word_bottle, word_can,  word_draft ):\n",
    "    # Read the list of words from the text file\n",
    "    with open(word_can, 'r') as file:\n",
    "        word_can = file.read().splitlines()\n",
    "\n",
    "    with open(word_bottle, 'r') as file:\n",
    "        word_bottle = file.read().splitlines()\n",
    "\n",
    "    with open(word_draft, 'r') as file:\n",
    "        word_draft = file.read().splitlines()\n",
    "\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # Transform the review and words list using TF-IDF\n",
    "    tfidf_matrix = vectorizer.fit_transform([review])\n",
    "\n",
    "    can_vector = vectorizer.transform([\" \".join(word_can)])\n",
    "    bottle_vector = vectorizer.transform([\" \".join(word_bottle)])\n",
    "    draft_vector = vectorizer.transform([\" \".join(word_draft)])\n",
    "\n",
    "    #Calculate the cosine similarity\n",
    "    cosine_sim_can = cosine_similarity(tfidf_matrix, can_vector)\n",
    "    cosine_sim_bottle = cosine_similarity(tfidf_matrix, bottle_vector)\n",
    "    cosine_sim_draft = cosine_similarity(tfidf_matrix, draft_vector)\n",
    "\n",
    "    return cosine_sim_bottle, cosine_sim_can, cosine_sim_draft\n",
    "\n",
    "# Example usage\n",
    "text = df.sample(1)['text'].values[0].lower()\n",
    "print(text, '\\n')\n",
    "word_bottle = \"data/bottle.txt\"\n",
    "word_can = \"data/can.txt\"\n",
    "word_draft = \"data/draft.txt\"\n",
    "\n",
    "cosine_sim_bottle, cosine_sim_can, cosine_sim_draft = calculate_similarity(text, word_bottle, word_can,  word_draft )\n",
    "print(\"Cosine similarity for bottle:\", cosine_sim_bottle[0][0])\n",
    "print(\"Cosine similarity for can:\", cosine_sim_can[0][0])\n",
    "print(\"Cosine similarity for draft:\", cosine_sim_draft[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "It seems to work for most reviews. It might be interesting to save this feature in the reviews df and compare it to the naive method. \n",
    "\n",
    "For a few example, two similarity score seems to come close. <br>\n",
    "<hr>\n",
    "\n",
    "*poured from a 500 ml bottle into a nonic pint. excellent label of a beer-swilling elephant riding a steam engine. a hilariously sick tribute to local martyr &quot;jumbo&quot;, p.t. barnum's famous elephant, who was crushed to death by a train in st. thomas in the 1880's.deep, clear gold tending toward amber, with a tight creamy head that eventually settles down to a soft, white collar. good lacing.smell is some spicy, piney c-hop; sweet, toffee-like malt; and on the fainter side.taste follows smell. the principal malt character is toffee-like sweetness. intensely sweet upfront, followed by a prickly bitterness that smooths out on the way down and rears its head in the lingering, bittersweet aftertaste. it actually leans toward sweet to the point of underbalance, if only slightly. the faintest hints of staleness/infection (one of the flavors i'm actually quite good at picking out), but nothing serious.mouthfeel is moderate/full, lighter carbonation, refreshing.only okay drinkability. i can't put my finger on it, but with every sip i find myself wanting less. it's definitely leans toward the sticky-sweet, so maybe that's why.one of the better beers from ironspike. good to try, but i wouldn't go out of my way for it.*\n",
    "\n",
    "\n",
    "It gave the following similarity score: \n",
    "\n",
    "can : 0.0\n",
    "\n",
    "bottle : 0.0686369473085648 (because of bottle)\n",
    "\n",
    "draft : 0.07000595987603604 (because of pint)\n",
    "\n",
    "The label should be \"bottle\", but it's still interesting that this user drank it from a glass. The difference in those moments might be interesting to look at\n",
    "\n",
    "\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Interesting observation:</b> Apparently, most of the time the users who had it on can or bottle serve it nonetheless on a glass -> Probably interesting to look at later.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 3 new columns (each service type) with the similarity score for each review\n",
    "# takes really long, more than 30 minutes\n",
    "df[['similarity_bottle', 'similarity_can', 'similarity_draft']] = df['text'].apply(lambda x: pd.Series(calculate_similarity(x, word_bottle, word_can, word_draft)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive and negative word lists\n",
    "with open(\"data/positive.txt\", \"r\") as f:\n",
    "    positive_words = f.read().splitlines()\n",
    "\n",
    "with open(\"data/negative.txt\", \"r\") as f:\n",
    "    negative_words = f.read().splitlines()\n",
    "    \n",
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.sample(1)['text'].values[0].lower()\n",
    "print(text)\n",
    "\n",
    "### textblob\n",
    "print('Polarity textblob:',TextBlob(text).sentiment.polarity)\n",
    "# print('Subjectivity:',TextBlob(text).sentiment.subjectivity)\n",
    "\n",
    "### TF-IDF\n",
    "# Fit and transform the review text\n",
    "tfidf_matrix = vectorizer.fit_transform([text])\n",
    "\n",
    "# Calculate the cosine similarity between the review and positive/negative word vectors\n",
    "positive_vector = vectorizer.transform([\" \".join(positive_words)])\n",
    "negative_vector = vectorizer.transform([\" \".join(negative_words)])\n",
    "\n",
    "cosine_sim_pos = cosine_similarity(tfidf_matrix, positive_vector)\n",
    "cosine_sim_neg = cosine_similarity(tfidf_matrix, negative_vector)\n",
    "\n",
    "# Calculate the polarity score\n",
    "polarity_score = cosine_sim_pos - cosine_sim_neg\n",
    "\n",
    "print(\"Polarity tf-idf:\", polarity_score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function who does the textblob and tf-idf polarity score for each review\n",
    "\n",
    "def polarity_score(review, positive_vector, negative_vector):\n",
    "    # textblob\n",
    "    polarity_textblob = TextBlob(review).sentiment.polarity\n",
    "    # tf-idf\n",
    "    #tfidf_matrix = vectorizer.fit_transform([review])\n",
    "    #positive_vector = vectorizer.transform([\" \".join(positive_words)])\n",
    "    #negative_vector = vectorizer.transform([\" \".join(negative_words)])\n",
    "    #cosine_sim_pos = cosine_similarity(tfidf_matrix, positive_vector)\n",
    "    #cosine_sim_neg = cosine_similarity(tfidf_matrix, negative_vector)\n",
    "    #polarity_tfidf = cosine_sim_pos - cosine_sim_neg\n",
    "    return polarity_textblob #, polarity_tfidf[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns for the textblob and tf-idf polarity score for each review\n",
    "#took 6min to run\n",
    "#df[['polarity_textblob', 'polarity_tfidf']] = df['text'].apply(lambda x: pd.Series(polarity_score(x, positive_vector, negative_vector)))\n",
    "df[['polarity_textblob']] = df['text'].apply(lambda x: pd.Series(polarity_score(x, positive_vector, negative_vector)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export df to csv   \n",
    "df.to_csv(dataset_path + 'BeerAdvocateMerged2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data filtering üßπ\n",
    "Number of valid reviews per beer and users & average rating per beer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering on amount of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the number of valid reviews per user\n",
    "df['user_nbr_reviews_computed'] = df.groupby('user_id')['user_id'].transform('count')\n",
    "\n",
    "# compute the number of valid reviews per beer\n",
    "df['beer_nbr_reviews_computed'] = df.groupby('beer_id')['beer_id'].transform('count')\n",
    "\n",
    "# compute the avg rating per beer\n",
    "df['beer_avg_computed'] = df.groupby('beer_id')['rating'].transform('mean')\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# group the reviews by beer_id and show a histogram of the number of reviews computed\n",
    "plt.subplot(1, 2, 1)\n",
    "df.groupby('beer_id')['beer_nbr_reviews_computed'].mean().hist(bins=100, log=True)\n",
    "plt.xlabel('Number of reviews per beer')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# group the reviews by user_id and show a histogram of the number of reviews computed\n",
    "plt.subplot(1, 2, 2)\n",
    "df.groupby('user_id')['user_nbr_reviews_computed'].mean().hist(bins=100, log=True)\n",
    "plt.xlabel('Number of reviews per user')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering to remove users and beers with less reviews\n",
    "\n",
    "min_nbr_reviews_per_user = 0\n",
    "min_nbr_reviews_per_beer = 20\n",
    "\n",
    "len0 = df.shape[0]\n",
    "\n",
    "# remove every row where the number of reviews per user is less than min_nbr_reviews_per_user\n",
    "df_filter = df[df['user_nbr_reviews_computed'] >= min_nbr_reviews_per_user].copy(deep=True)\n",
    "\n",
    "# remove every row where the number of reviews per beer is less than min_nbr_reviews_per_beer\n",
    "df_filter_full = df_filter[df_filter['beer_nbr_reviews_computed'] >= min_nbr_reviews_per_beer].copy(deep=True)\n",
    "\n",
    "print('We removed {} rows, leaving us with {} %% of the original dataset'.format(len0 - df_filter_full.shape[0], round(df_filter_full.shape[0] / len0 * 100, 2)))\n",
    "print('We have {} valid reviews'.format(df_filter_full.shape[0]))\n",
    "\n",
    "# print the number of reviews for each serving type\n",
    "df_filter_full['serving_type'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter on readability score of the reviews üìù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_filter_full.sample(n=1000, random_state=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['readability_score'] = df_sample['text'].apply(lambda x: flesch_reading_ease(x) if isinstance(x, str) else None)\n",
    "df_sample['readability_score'].hist(bins=100, figsize=(15, 5), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing some reviews based on readability score\n",
    "\n",
    "df_sample[df_sample['readability_score'] < 20]['text'].count()\n",
    "\n",
    "# for row in df_sample[df_sample['readability_score'] > 96]['text']:\n",
    "#     print(row)\n",
    "#     print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reviews with bad readability score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the serving mode with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#250 reviews for function evaluation (manually labelled)\n",
    "df_eval = df.sample(n=250, random_state=46).copy(deep=True)\n",
    "df_eval['true_serving_type'] = 'not_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in 5 parts\n",
    "df_eval_tristan = df_eval.iloc[:50].copy(deep=True)\n",
    "df_eval_av = df_eval.iloc[50:100].copy(deep=True)\n",
    "df_eval_victor = df_eval.iloc[100:150].copy(deep=True)\n",
    "df_eval_thamin = df_eval.iloc[150:200].copy(deep=True)\n",
    "df_eval_agatha = df_eval.iloc[200:].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_review(df):\n",
    "    # filter the dataframe to only include rows where 'true_serving_type' is 'unknown'\n",
    "    df_not_set = df[df['true_serving_type'] == 'not_set']\n",
    "    if len(df_not_set) == 0:\n",
    "        print('No more reviews to label')\n",
    "        return None\n",
    "    else:\n",
    "        # print the 'text' column of the first row with unknown serving type\n",
    "        index = df_not_set.index[0]\n",
    "        print(f\"Review {index}:\\n{df_not_set.loc[index, 'text']}\")\n",
    "        \n",
    "        return index\n",
    "\n",
    "def update_review_serving_type(df, index):\n",
    "    # ask the user to input the serving type\n",
    "    if index is None:\n",
    "        return df\n",
    "    else:\n",
    "        serving_type = input(\"Enter the serving type (bottle/can/draft/unknown): \")\n",
    "        if serving_type not in ['bottle', 'can', 'draft', 'unknown']:\n",
    "            print('Invalid serving type')\n",
    "            return df\n",
    "        else:\n",
    "            # update the 'true_serving_type' column of the review with the given index\n",
    "            df.loc[index, 'true_serving_type'] = serving_type\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more reviews to label\n"
     ]
    }
   ],
   "source": [
    "# Manual labelling Tristan\n",
    "idx = display_review(df_eval_tristan)\n",
    "df_eval_tristan = update_review_serving_type(df_eval_tristan, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to save true labels\n",
    "# df_eval_tristan.to_csv('BeerAdvocateEvalTristan.csv', index=True)\n",
    "df_eval_tristan = pd.read_csv('BeerAdvocateEvalTristan.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_serving_type\n",
       "unknown    26\n",
       "bottle     22\n",
       "draft       1\n",
       "can         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_tristan['true_serving_type'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual labelling AV\n",
    "idx = display_review(df_eval_av)\n",
    "df_eval_av = update_review_serving_type(df_eval_av, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual labelling Victor\n",
    "idx = display_review(df_eval_victor)\n",
    "df_eval_av = update_review_serving_type(df_eval_victor, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual labelling Thamin\n",
    "idx = display_review(df_eval_thamin)\n",
    "df_eval_av = update_review_serving_type(df_eval_thamin, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual labelling Agatha\n",
    "idx = display_review(df_eval_agatha)\n",
    "df_eval_av = update_review_serving_type(df_eval_agatha, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original functions\n",
    "\n",
    "def differentiate_can(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    verbes_nom=[]\n",
    "    for token in doc:\n",
    "        if token.text.lower() == \"can\":\n",
    "            if any(t.dep_ == \"aux\" for t in token.head.children):\n",
    "                verbes_nom .append(\"verb\")\n",
    "            else:\n",
    "                verbes_nom .append(\"noun\") \n",
    "    \n",
    "    return verbes_nom\n",
    "\n",
    "def remove_conditional(review):\n",
    "    # Tokenize the review\n",
    "    doc = nlp(review)\n",
    "\n",
    "    modified_tokens = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        remove_sentence = False\n",
    "        for token in sent:\n",
    "            if remove_sentence:\n",
    "                continue\n",
    "            if token.text.lower() == \"would\" or token.text.lower() == \"could\":\n",
    "                # Identify the subtree dependent on the conditional word\n",
    "                subtree = [t.text for t in token.subtree]\n",
    "                # Join the modified tokens to form the modified text\n",
    "                modified_tokens.extend(subtree[:-1])  # Exclude the conditional word itself\n",
    "                remove_sentence = True\n",
    "            else:\n",
    "                modified_tokens.append(token.text)\n",
    "\n",
    "    # Join the modified tokens to form the modified text\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "def extract_serving_style(review):\n",
    "    serving_style = 'unknown'\n",
    "    # Tokenize the review\n",
    "    modified_review = remove_conditional(review)\n",
    "    modified_words = nlp(modified_review)\n",
    "    bottle = ['bottle', 'bottled', 'bottles', 'growler']\n",
    "    can = ['can', 'canned', ' cans ']\n",
    "    draft = ['draft', 'draught', 'tap', 'taps']\n",
    "\n",
    "    serving_styles = []\n",
    "\n",
    "    for word in modified_words:\n",
    "        # If the word is a serving style, add it to the list\n",
    "        if word.text.lower() in bottle:\n",
    "            serving_styles.append(\"bottle\")\n",
    "        if word.text.lower() in can:\n",
    "            serving_styles.append(\"can\")\n",
    "        if word.text.lower() in draft:\n",
    "            serving_styles.append(\"draft\")\n",
    "    \n",
    "    #If the list contains \"can\" we need to check the output of differentiate_can to see if there are several instances of \"can\". If it is at least one instance of \"can\" as a noun, we keep \"can\" in \"serving_styles\", otherwise we remove it\n",
    "    if \"can\" in serving_styles:\n",
    "        if \"noun\" in differentiate_can(modified_review):\n",
    "            serving_styles = serving_styles\n",
    "        else:\n",
    "            serving_styles.remove(\"can\")\n",
    "    \n",
    "\n",
    "    # If the list contains more than one different serving style, we put \"unknown\"\n",
    "    if len(set(serving_styles)) > 1:\n",
    "        serving_style = \"unknown\"\n",
    "    # If the list contains only one serving style, we put this serving style\n",
    "    elif len(set(serving_styles)) == 1:\n",
    "        serving_style = serving_styles[0]\n",
    "    \n",
    "    return serving_style\n",
    "\n",
    "# Accuracy function\n",
    "def compute_accuracy(predictions, true_classes):\n",
    "    correct_count = 0\n",
    "    total_count = len(predictions)\n",
    "\n",
    "    for pred, true_class in zip(predictions, true_classes):\n",
    "        if pred=='unknwon' and true_class=='unknown':\n",
    "            correct_count += 1\n",
    "        elif pred == true_class:\n",
    "            correct_count += 1\n",
    "\n",
    "    accuracy = correct_count / total_count if total_count > 0 else 0.0\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-improved\n",
    "\n",
    "def gpt_differentiate_can(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    verbes_nom = []\n",
    "    for token in doc:\n",
    "        if token.text.lower() == \"can\" and any(t.dep_ == \"aux\" for t in token.head.children):\n",
    "            verbes_nom.append(\"verb\")\n",
    "        elif token.text.lower() == \"can\":\n",
    "            verbes_nom.append(\"noun\")\n",
    "\n",
    "    return verbes_nom\n",
    "\n",
    "def gpt_remove_conditional(review):\n",
    "    doc = nlp(review)\n",
    "    \n",
    "    modified_tokens = []\n",
    "    remove_sentence = False\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            if remove_sentence:\n",
    "                continue\n",
    "            if token.text.lower() in {\"would\", \"could\"}:\n",
    "                subtree = [t.text for t in token.subtree]\n",
    "                modified_tokens.extend(subtree[:-1])\n",
    "                remove_sentence = True\n",
    "            else:\n",
    "                modified_tokens.append(token.text)\n",
    "\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text\n",
    "\n",
    "def gpt_extract_serving_style(review):\n",
    "    bottle = {'bottle', 'bottled', 'bottles', 'growler'}\n",
    "    can = {'can', 'canned', 'cans'}\n",
    "    draft = {'draft', 'draught', 'tap', 'taps'}\n",
    "\n",
    "    modified_review = gpt_remove_conditional(review)\n",
    "    modified_words = nlp(modified_review)\n",
    "\n",
    "    serving_styles = []\n",
    "    for word in modified_words:\n",
    "        # If the word is a serving style, add it to the list\n",
    "        if word.text.lower() in bottle:\n",
    "            serving_styles.append(\"bottle\")\n",
    "        if word.text.lower() in can:\n",
    "            serving_styles.append(\"can\")\n",
    "        if word.text.lower() in draft:\n",
    "            serving_styles.append(\"draft\")\n",
    "\n",
    "    if \"can\" in serving_styles and \"noun\" not in gpt_differentiate_can(modified_review):\n",
    "        serving_styles.remove(\"can\")\n",
    "\n",
    "    serving_style = serving_styles[0] if len(set(serving_styles)) == 1 else 'unknown'\n",
    "\n",
    "    return serving_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run the function on 50 reviews: 2.75111 seconds\n",
      "Accuracy: 0.96\n",
      "Time needed to run the function on 2557577 reviews: 39.1 hours\n"
     ]
    }
   ],
   "source": [
    "# extract serving style for each review\n",
    "t1 = time.time()\n",
    "df_eval_tristan['extracted_serving_type'] = df_eval_tristan['text'].apply(lambda x: extract_serving_style(x))\n",
    "t2 = time.time()\n",
    "print('Time to run the function on {} reviews: {} seconds'.format(len(df_eval_tristan), round(t2 - t1, 5)))\n",
    "print('Accuracy:', compute_accuracy(df_eval_tristan['extracted_serving_type'], df_eval_tristan['true_serving_type']))\n",
    "\n",
    "time_needed = (len(df) / len(df_eval_tristan)) * (t2 - t1)\n",
    "print('Time needed to run the function on {} reviews: {} hours'.format(len(df), round(time_needed/3600, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run the function on 50 reviews: 2.21757 seconds\n",
      "Accuracy: 0.96\n",
      "Time needed to run the function on 2557577 reviews: 31.5 hours\n"
     ]
    }
   ],
   "source": [
    "# extract serving style for each review with gpt functions\n",
    "t1 = time.time()\n",
    "df_eval_tristan['gpt_extracted_serving_type'] = df_eval_tristan['text'].apply(lambda x: gpt_extract_serving_style(x))\n",
    "t2 = time.time()\n",
    "print('Time to run the function on {} reviews: {} seconds'.format(len(df_eval_tristan), round(t2 - t1, 5)))\n",
    "print('Accuracy:', compute_accuracy(df_eval_tristan['gpt_extracted_serving_type'], df_eval_tristan['true_serving_type']))\n",
    "\n",
    "time_needed = (len(df) / len(df_eval_tristan)) * (t2 - t1)\n",
    "print('Time needed to run the function on {} reviews: {} hours'.format(len(df), round(time_needed/3600, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 2148077:\n",
      "poured from 12 oz. bottledeep reddish mahogany or dark amber honey colored with enough haze to render it opaque. creamy off-white head that left chunky bits of lacing stuck to the inside of the glass all the way to the bottom. light floral scent with malt wafting though and a faint tingle on the nose suggesting hops content. tasted caramel and nut flavors in the initial sweet malt impression - toasty. bitterness creeps in soon after adding bite to the malt before crushing it with a heavy hops burst mid-palate. strong finish that is noticably more hops than malt (despite the touted &quot;balanced finish&quot;) and has great lingering power. felt smooth at first, then more medium-bodied and a bit chewier or oily. appropriate carbonation. very decent brew if you're in the mood for something less pale with plenty of hops.\n",
      "Extracted serving type: unknown\n",
      "True serving type: bottle\n",
      "----------------------\n",
      "Review 1170193:\n",
      "this beer is meant to drink from the can - my quintessential camping, fishing beer - so much better than other macro products- i've had it on tap, but i gotta say, i like it better straight out of the can, and pretty cold at that - by those standards, this is my favorite all-day beer in the spring and summer months - a greatvalue in a sweet beer!\n",
      "Extracted serving type: unknown\n",
      "True serving type: can\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# loop through the mismatched rows\n",
    "for index, row in df_eval_tristan[df_eval_tristan['extracted_serving_type'] != df_eval_tristan['true_serving_type']].iterrows():\n",
    "    print(f\"Review {index}:\\n{row['text']}\\nExtracted serving type: {row['extracted_serving_type']}\\nTrue serving type: {row['true_serving_type']}\")\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial examples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = \"Had a can. Would love to try it on tap, and maybe in a bottle.\"\n",
    "ex2 = \"I had a bottle of beer and a can of coke\"\n",
    "ex3 = \"Can I go to the bathroom I had a beer in a can even if I would have prefered it served by draft because I can.\"\n",
    "ex4 = \"Can I go to the bathroom I had a beer in a can even if I would have prefered it served by draft because I can. Next time, I will try a bottle.\"\n",
    "ex_review = str(\"Find this one whenever you can.\")\n",
    "print(extract_serving_style(ex))\n",
    "print(extract_serving_style(ex2))\n",
    "print(extract_serving_style(ex3))\n",
    "print(extract_serving_style(ex4))\n",
    "print(differentiate_can(ex_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut supprimer ca ?   \n",
    "Test on real reviews : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT DELETE THIS CELL: used for testing below\n",
    "df_nlp = df.sample(n=1000, random_state=46).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "test = df_nlp.sample(15, random_state=46).copy(deep=True)\n",
    "test['serving_style'] = test['text'].apply(lambda x: extract_serving_style(x))\n",
    "t2 = time.time()\n",
    "print('Time to run the function on 10 reviews :', round(t2 - t1, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled by hand to check if the function works well\n",
    "true_SS = ['bottle', 'bottle', None, 'draft', None, 'bottle', 'bottle', 'bottle', None, 'bottle', 'bottle', None, None, 'bottle', 'bottle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['serving_style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy : {compute_accuracy(test['serving_style'], true_SS)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries grouping üåç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('data/countries.csv', usecols=['name', 'region', 'sub-region'])\n",
    "countries.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some reviews for each serving type\n",
    "print('Reviews with bottle:\\n')\n",
    "for text in df[df['serving_type'] == 'bottle']['text'].sample(1):\n",
    "    print(text)\n",
    "    print('----------------------')\n",
    "print('Reviews with can:\\n')\n",
    "for text in df[df['serving_type'] == 'can']['text'].sample(1):\n",
    "    print(text)\n",
    "    print('----------------------')\n",
    "print('Reviews with draft:\\n')\n",
    "for text in df[df['serving_type'] == 'draft']['text'].sample(1):\n",
    "    print(text)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the average value of the rating for each serving type\n",
    "comp_str = 'rating'\n",
    "print('Average ' + comp_str + ' for bottle: ', round(df[df['serving_type'] == 'bottle'][comp_str].mean(), 3))\n",
    "print('Average ' + comp_str + ' for can: ', round(df[df['serving_type'] == 'can'][comp_str].mean(), 3))\n",
    "print('Average ' + comp_str + ' for draft: ', round(df[df['serving_type'] == 'draft'][comp_str].mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show boxplot and histograms of ratings for bottle, can and draft\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(121)\n",
    "sns.boxplot(data=df, hue='serving_type', y='rating')\n",
    "plt.subplot(122)\n",
    "sns.histplot(data=df, hue='serving_type', x='rating', kde=True, bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis üìà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the impact of each aspect on rating üìè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a linear regression line to the data for all 5 aspects\n",
    "reg1 = LinearRegression().fit(df[['appearance']], df['rating'])\n",
    "reg2 = LinearRegression().fit(df[['aroma']], df['rating'])\n",
    "reg3 = LinearRegression().fit(df[['palate']], df['rating'])\n",
    "reg4 = LinearRegression().fit(df[['taste']], df['rating'])\n",
    "reg5 = LinearRegression().fit(df[['overall']], df['rating'])\n",
    "\n",
    "# create subplots for all 5 aspects\n",
    "fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "# plot the data and regression line for each aspect\n",
    "sns.scatterplot(data=df, x='appearance', y='rating', s=0.5, ax=axs[0])\n",
    "axs[0].plot(df[['appearance']], reg1.predict(df[['appearance']]), color='red')\n",
    "axs[0].set_title('Appearance\\nSlope = ' + str(round(reg1.coef_[0], 3)) + '\\nR2 = ' + str(round(reg1.score(df[['appearance']], df['rating']), 3)))\n",
    "\n",
    "sns.scatterplot(data=df, x='aroma', y='rating', s=0.5, ax=axs[1])\n",
    "axs[1].plot(df[['aroma']], reg2.predict(df[['aroma']]), color='red')\n",
    "axs[1].set_title('Aroma\\nSlope = ' + str(round(reg2.coef_[0], 3)) + '\\nR2 = ' + str(round(reg2.score(df[['aroma']], df['rating']), 3)))\n",
    "\n",
    "sns.scatterplot(data=df, x='palate', y='rating', s=0.5, ax=axs[2])\n",
    "axs[2].plot(df[['palate']], reg3.predict(df[['palate']]), color='red')\n",
    "axs[2].set_title('Palate\\nSlope = ' + str(round(reg3.coef_[0], 3)) + '\\nR2 = ' + str(round(reg3.score(df[['palate']], df['rating']), 3)))\n",
    "\n",
    "sns.scatterplot(data=df, x='taste', y='rating', s=0.5, ax=axs[3])\n",
    "axs[3].plot(df[['taste']], reg4.predict(df[['taste']]), color='red')\n",
    "axs[3].set_title('Taste\\nSlope = ' + str(round(reg4.coef_[0], 3)) + '\\nR2 = ' + str(round(reg4.score(df[['taste']], df['rating']), 3)))\n",
    "\n",
    "sns.scatterplot(data=df, x='overall', y='rating', s=0.5, ax=axs[4])\n",
    "axs[4].plot(df[['overall']], reg5.predict(df[['overall']]), color='red')\n",
    "axs[4].set_title('Overall\\nSlope = ' + str(round(reg5.coef_[0], 3)) + '\\nR2 = ' + str(round(reg5.score(df[['overall']], df['rating']), 3)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# should still add confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like Taste as the biggest impact on the rating while appearance has the least impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing on the new labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_ttest(type1, type2, category):\n",
    "    ttest = ttest_ind(df[df['serving_type'] == type1][category],df[df['serving_type'] == type2][category])\n",
    "    if ttest[1] > 0.05:\n",
    "        print('The p-value is high (' + str(ttest[1]) + '), so we cannot reject the null hypothesis that the two samples have the same average')\n",
    "    else:\n",
    "        print('The p-value is very low (' + str(ttest[1]) + '), so we can reject the null hypothesis that the two samples have the same average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the columns to compare\n",
    "columns = ['appearance', 'aroma', 'palate', 'taste', 'overall', 'rating']\n",
    "\n",
    "# create an empty matrix to store the p-values\n",
    "p_values = np.zeros((len(columns), 3))\n",
    "\n",
    "# perform the t-test and store the p-values in the matrix\n",
    "for i in range(len(columns)):\n",
    "    ttest1 = ttest_ind(df[df['serving_type'] == 'bottle'][columns[i]], df[df['serving_type'] == 'can'][columns[i]])\n",
    "    ttest2 = ttest_ind(df[df['serving_type'] == 'can'][columns[i]], df[df['serving_type'] == 'draft'][columns[i]])\n",
    "    ttest3 = ttest_ind(df[df['serving_type'] == 'draft'][columns[i]], df[df['serving_type'] == 'bottle'][columns[i]])\n",
    "    p_values[i][0] = ttest1[1]\n",
    "    p_values[i][1] = ttest2[1]\n",
    "    p_values[i][2] = ttest3[1]\n",
    "\n",
    "# create the grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(columns))\n",
    "width = 0.25\n",
    "rects1 = ax.bar(x - width, p_values[:,0], width, label='Bottle vs Can')\n",
    "rects2 = ax.bar(x, p_values[:,1], width, label='Can vs Draft')\n",
    "rects3 = ax.bar(x + width, p_values[:,2], width, label='Draft vs Bottle')\n",
    "ax.set_xticks(x)\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xticklabels(columns)\n",
    "ax.set_ylabel('p-value')\n",
    "ax.set_title('Comparison of Aspects between Service Types')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the p-values are below 0.05 (expect 1), so we can reject the null hypothesis and conclude that there is a significant difference between the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test for aroma betwwen draft and bottle\n",
    "do_ttest('draft', 'bottle', 'aroma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a boxplot of aroma for draft and bottle\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[df['serving_type'].isin(['draft', 'bottle'])], x='serving_type', y='aroma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
